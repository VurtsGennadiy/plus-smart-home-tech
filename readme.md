![Java](https://img.shields.io/badge/Java-ED8B00?style=for-the-badge&logo=openjdk&logoColor=white)
![Maven](https://img.shields.io/badge/Apache_Maven-C71A36?style=for-the-badge&logo=apache-maven&logoColor=white)
![Spring Boot](https://img.shields.io/badge/Spring_Boot-6DB33F?style=for-the-badge&logo=spring&logoColor=white)
![PostgreSQL](https://img.shields.io/badge/PostgreSQL-316192?style=for-the-badge&logo=postgresql&logoColor=white)
![Kafka](https://img.shields.io/badge/Apache_Kafka-231F20?style=for-the-badge&logo=apachekafka&logoColor=white)
![gRPC](https://img.shields.io/badge/gRPC-4285F4?style=for-the-badge&logo=google&logoColor=white)

## Модуль commerce

Интернет - магазин для продажи устройств умного дома.

Используя паттерн _Decompose by Business Capability_, выделены шесть ключевых микросервисов:
* `shopping-store` — представляет собой витрину товаров, из которых пользователи выбирают товары для заказа.
* `shopping-cart` — отвечает за работу с корзиной пользователей. Пользователи будут добавлять товары в корзину, чтобы сделать заказ.
* `order` — работает с заказами пользователей, оформляет их.
* `warehouse` — отвечает за склад.
* `payment` — адаптер к платежному сервису.
* `delivery` — адаптер к службе доставки.

Взаимодействие микросервисов между собой осуществляется с помощью _REST_ - вызовов, для этого используются _Feign_ - клиенты. 

[Open API спецификация](docs/api)

Для работы с данными реализован паттерн _Database per Service_. Паттерн реализован на уровне схем БД: сервер базы данных для всего приложения общий,
но каждый микросервис работает со своей схемой.

Схематически взаимодействие микросервисов можно представить так:
![схема взаимодействия сервисов commerce](docs/img/commerce_app_schema.png)

[Описание жизненного цикла заказа](docs/order_lifecycle.md)

Вспомогательный модуль **interaction-api** содержит компоненты необходимые для взаимодействия основных сервисов, а также их общие компоненты,
а именно: Feign клиенты, DTO - классы, общие исключения, а также глобальный _ControllerAdvice_ для их обработки. Также в этом модуле находится
кастомная аннотация @Loggable для логирования входа и выхода из методов и её реализация, основанная на Spring AOP.

---

## Модуль infra

Модуль infra содержит компоненты инфрастуктуры приложения, и включает микросервисы:
* `discovery-server` — сервер регистрации и обнаружения сервисов на базе `Spring Cloud Eureka`.
  Все микросервисы при старте регистрируются в Eureka с динамическими именами и сетевыми адресами.
  Последующие вызовы между сервисами (FeignClient, RestTemplate) выполняются по имени сервиса, вместо жёстко заданного URL.
* `config-server` — сервер конфигурации на базе `Spring Cloud Config Server`. Централизованное хранение и доставка конфигураций сервисов.
* `gateway-server` — API-шлюз для маршрутизации запросов, `Spring Cloud Gateway`.

---

## Модуль telemetry

Платформа для сбора и анализа данных от датчиков умного дома. На вход подаются данные датчиков, а основная задача 
приложения — собрать эту информацию, обработать и определить, какие сценарии умного дома необходимо запустить.

Например, если поступил сигнал, что в комнате без света сработал датчик движения, то нужно включить конкретную лампочку.

* обрабатывает данные со всех проданных датчиков;
* трансформирует их в нужный формат;
* хранит описание сценариев: какую команду запустить и при каких показателях от конкретных датчиков;
* определяет необходимость запуска этих сценариев.


  Приложение состоит из нескольких микросервисов:
* **Hub router**. Хаб — это устройство, которое пользователь устанавливает у себя дома. К нему присоединяются остальные датчики, приобретённые пользователем.

Датчик температуры, освещённости или умный выключатель — любой датчик, расположенный в пределах квартиры или дома, подключается к хабу по технологии Zigbee. 
Все они передают свои показания хабу, а хаб подключается к сети Интернет по Wi-Fi и отправляет данные в систему.
Данные от хабов пользователей принимает сервис Hub router. Он преобразует эти данные в понятные системе сообщения и направляет в другой сервис — Collector. 
В рамках проекта сервис Hub router не реализован.

* **[Collector.](#сервис-collector)** Принимает данные каждого пользовательского хаба, которые передаёт Hub router. Преобразовывает их в формат Apache Avro и сохраняет в топик Apache Kafka. Далее из этого топика данные могут считывать другие сервисы для своих нужд.
* **[Aggregator](#сервис-aggregator)**. Считывает показания всех датчиков из топика Kafka и агрегирует по признаку принадлежности к хабу. Так получается снимок состояния всех датчиков, расположенных в пределах квартиры или дома. Результат агрегации записывается в топик Kafka.
* **[Analyzer](#сервис-analyzer)**. Считывает агрегированное состояние датчиков в квартире или доме и проверяет, соответствует ли оно условиям какого-либо сценария для этого дома.
Если состояние датчиков соответствует сценарию, то он запускается на выполнение, и Analyzer отправляет команды в Hub router. 
Hub router, в свою очередь, отправляет в нужный хаб указания выполнить конкретные действия.

Верхнеуровнево схема приложения выглядит так:
![Схема приложения](docs/img/telemetry_app_schema.png)


Maven cтруктура проекта содержит три верхнеуровневых модуля:
* _telemetry_. Сервисы, связанные с обработкой телеметрических данных, то есть показаний датчиков. 
Состоит из нескольких подмодулей:
    * _[collector](#сервис-collector)_ - код сервиса, сохраняющего в топики Kafka данные от датчиков и хабов.
    * _[aggregator](#сервис-aggregator)_ - код сервиса, агрегирующего показатели датчиков.
    * _[analyzer](#сервис-analyzer)_ - код сервиса, проверяющего условия выполнения сценариев.
    * _serialization_ — родительский Maven-модуль, объединяющий модули со схемами Avro и Protobuf:
      * avro-schemas — схемы Avro и сгенерированные на их основе классы;
      * proto-schemas — схемы Protobuf и сгенерированные на их основе классы.
* _infra_. Maven-модуль, в котором будут инфраструктурные компоненты. _В разработке._
* _commerce_. Maven-модуль, включающий сервисы для поддержки продаж устройств умного дома. _В разработке._


### Сервис Collector

Принимает данные от хабов пользователей.

Сервис работает в качестве gRPC-сервера и реализует RPC API с двумя методами:
- _CollectSensorEvent_ — позволяет передать события от устройств, подключённых к хабу;
- _CollectHubEvent_ — позволяет передать события, связанные с хабом или сценариями умного дома.

Через gRPC-сервис данные передаются в двоичном виде в формате Protobuf.
Полученные данные записываются в топики Kafka:
- _telemetry.sensors.v1_ — для событий от устройств;
- _telemetry.hubs.v1_ — для событий, связанных с хабами или сценариями умного дома.

События от датчиков, подключённых к хабу. К ним относятся показания:
* датчика освещённости,
* датчика температуры,
* умного переключателя (это может быть выключатель света или лампочка с двумя состояниями: «вкл» и «выкл»),
* климатического датчика,
* датчика движения.

События, связанные с хабом или сценариями умного дома. К ним относятся:
* регистрация и дерегистрация в хабе нового датчика,
* добавление и удаление сценария умного дома.

### Сервис Aggregator

- Сервис работает в роли потребителя данных из топика _telemetry.sensors.v1_ и производителя данных в топик _telemetry.snapshots.v1_.
- Читает события от устройств, подключённых к хабу, и агрегирует их в снапшот состояний.
- Каждый снапшот содержит последние показания датчиков, подключённых к конкретному хабу. В снапшоте не может быть показаний от датчиков из разных хабов.
- Каждый раз, когда данные снапшота обновляются, его новая версия записывается в Kafka.
- Если очередное событие от одного из устройств не обновило данные ни одного из снапшотов, то в топик Kafka ничего не записывается.
- Сервис читает сообщения из Kafka, используя механизм групп потребителей.
- Данные записываются в Kafka в двоичном виде в формате Avro.
- Настройки консьюмера и продюсера можно изменить с помощью внешней конфигурации.

### Сервис Analyzer

- Читает события, связанные с хабом или сценариями умного дома из топика _telemetry.hubs.v1_. 
Полученные данные хранятся в БД PostgreSQL, используются JPA репозитории, [схема БД](docs/img/db_diagrams/analyzer_schema.png)
- Читает снапшоты состояния устройств, сгенерированные Aggregator, из топика _telemetry.snapshots.v1_.
- Анализирует полученные снапшоты - сверяет состояние умного дома с набором условий для сценариев.
- Если есть подходящий по условиям сценарий, то отправляет в Hub router gRPC сообщения для выполнения действий с конкретными устройствами.

Реализована многопоточная работа - чтение топиков и обработка сообщений производится в параллельных потоках, независимыми консюмерами:
- SnapshotProcessor — запускает цикл опроса и обработки снапшотов;
- HubEventProcessor — запускает цикл опроса и обработки событий добавления/удаления устройств и сценариев.

---

### Запуск приложения

0. Перед запуском приложения убедитесь, что у вас установлены Apache Maven и Docker.
1. Запустить Docker Desktop.
2. Запустить консоль в папке проекта.
3. Выполнить:
```bash
mvn clean package -DskipTests
docker-compose up --build -d
```
4. Готово! Приложение запущено на localhost:8080
