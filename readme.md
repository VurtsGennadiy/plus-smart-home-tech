![Java](https://img.shields.io/badge/Java-ED8B00?style=for-the-badge&logo=openjdk&logoColor=white)
![Maven](https://img.shields.io/badge/Apache_Maven-C71A36?style=for-the-badge&logo=apache-maven&logoColor=white)
![Spring Boot](https://img.shields.io/badge/Spring_Boot-6DB33F?style=for-the-badge&logo=spring&logoColor=white)
![PostgreSQL](https://img.shields.io/badge/PostgreSQL-316192?style=for-the-badge&logo=postgresql&logoColor=white)
![Kafka](https://img.shields.io/badge/Apache_Kafka-231F20?style=for-the-badge&logo=apachekafka&logoColor=white)
![gRPC](https://img.shields.io/badge/gRPC-4285F4?style=for-the-badge&logo=google&logoColor=white)


Платформа для сбора и анализа данных от датчиков умного дома. На вход подаются данные датчиков, а основная задача 
приложения — собрать эту информацию, обработать и определить, какие сценарии умного дома необходимо запустить.

Например, если поступил сигнал, что в комнате без света сработал датчик движения, то нужно включить конкретную лампочку.

* обрабатывает данные со всех проданных датчиков;
* трансформирует их в нужный формат;
* хранит описание сценариев: какую команду запустить и при каких показателях от конкретных датчиков;
* определяет необходимость запуска этих сценариев.


  Приложение состоит из нескольких микросервисов:
* **Hub router**. Хаб — это устройство, которое пользователь устанавливает у себя дома. К нему присоединяются остальные датчики, приобретённые пользователем.

Датчик температуры, освещённости или умный выключатель — любой датчик, расположенный в пределах квартиры или дома, подключается к хабу по технологии Zigbee. 
Все они передают свои показания хабу, а хаб подключается к сети Интернет по Wi-Fi и отправляет данные в систему.
Данные от хабов пользователей принимает сервис Hub router. Он преобразует эти данные в понятные системе сообщения и направляет в другой сервис — Collector. 
В рамках проекта сервис Hub router не реализован.

* **[Collector.](#сервис-collector)** Принимает данные каждого пользовательского хаба, которые передаёт Hub router. Преобразовывает их в формат Apache Avro и сохраняет в топик Apache Kafka. Далее из этого топика данные могут считывать другие сервисы для своих нужд.
* **[Aggregator](#сервис-aggregator)**. Считывает показания всех датчиков из топика Kafka и агрегирует по признаку принадлежности к хабу. Так получается снимок состояния всех датчиков, расположенных в пределах квартиры или дома. Результат агрегации записывается в топик Kafka.
* **[Analyzer](#сервис-analyzer)**. Считывает агрегированное состояние датчиков в квартире или доме и проверяет, соответствует ли оно условиям какого-либо сценария для этого дома.
Если состояние датчиков соответствует сценарию, то он запускается на выполнение, и Analyzer отправляет команды в Hub router. 
Hub router, в свою очередь, отправляет в нужный хаб указания выполнить конкретные действия.

Верхнеуровнево схема приложения выглядит так:
![Схема приложения](app_schema.png)


Maven cтруктура проекта содержит три верхнеуровневых модуля:
* _telemetry_. Сервисы, связанные с обработкой телеметрических данных, то есть показаний датчиков. 
Состоит из нескольких подмодулей:
    * _[collector](#сервис-collector)_ - код сервиса, сохраняющего в топики Kafka данные от датчиков и хабов.
    * _[aggregator](#сервис-aggregator)_ - код сервиса, агрегирующего показатели датчиков.
    * _[analyzer](#сервис-analyzer)_ - код сервиса, проверяющего условия выполнения сценариев.
    * _serialization_ — родительский Maven-модуль, объединяющий модули со схемами Avro и Protobuf:
      * avro-schemas — схемы Avro и сгенерированные на их основе классы;
      * proto-schemas — схемы Protobuf и сгенерированные на их основе классы.
* _infra_. Maven-модуль, в котором будут инфраструктурные компоненты. _В разработке._
* _commerce_. Maven-модуль, включающий сервисы для поддержки продаж устройств умного дома. _В разработке._


## Сервис Collector

Принимает данные от хабов пользователей.

Сервис работает в качестве gRPC-сервера и реализует RPC API с двумя методами:
- _CollectSensorEvent_ — позволяет передать события от устройств, подключённых к хабу;
- _CollectHubEvent_ — позволяет передать события, связанные с хабом или сценариями умного дома.

Через gRPC-сервис данные передаются в двоичном виде в формате Protobuf.
Полученные данные записываются в топики Kafka:
- _telemetry.sensors.v1_ — для событий от устройств;
- _telemetry.hubs.v1_ — для событий, связанных с хабами или сценариями умного дома.

События от датчиков, подключённых к хабу. К ним относятся показания:
* датчика освещённости,
* датчика температуры,
* умного переключателя (это может быть выключатель света или лампочка с двумя состояниями: «вкл» и «выкл»),
* климатического датчика,
* датчика движения.

События, связанные с хабом или сценариями умного дома. К ним относятся:
* регистрация и дерегистрация в хабе нового датчика,
* добавление и удаление сценария умного дома.

## Сервис Aggregator

- Сервис работает в роли потребителя данных из топика _telemetry.sensors.v1_ и производителя данных в топик _telemetry.snapshots.v1_.
- Читает события от устройств, подключённых к хабу, и агрегирует их в снапшот состояний.
- Каждый снапшот содержит последние показания датчиков, подключённых к конкретному хабу. В снапшоте не может быть показаний от датчиков из разных хабов.
- Каждый раз, когда данные снапшота обновляются, его новая версия записывается в Kafka.
- Если очередное событие от одного из устройств не обновило данные ни одного из снапшотов, то в топик Kafka ничего не записывается.
- Сервис читает сообщения из Kafka, используя механизм групп потребителей.
- Данные записываются в Kafka в двоичном виде в формате Avro.
- Настройки консьюмера и продюсера можно изменить с помощью внешней конфигурации.

## Сервис Analyzer

- Читает события, связанные с хабом или сценариями умного дома из топика _telemetry.hubs.v1_. 
Полученные данные хранятся в БД PostgreSQL, используются JPA репозитории, [схема БД](telemetry/analyzer/src/main/resources/ER-diagram.png)
- Читает снапшоты состояния устройств, сгенерированные Aggregator, из топика _telemetry.snapshots.v1_.
- Анализирует полученные снапшоты - сверяет состояние умного дома с набором условий для сценариев.
- Если есть подходящий по условиям сценарий, то отправляет в Hub router gRPC сообщения для выполнения действий с конкретными устройствами.

Реализована многопоточная работа - чтение топиков и обработка сообщений производится в параллельных потоках, независимыми консюмерами:
- SnapshotProcessor — запускает цикл опроса и обработки снапшотов;
- HubEventProcessor — запускает цикл опроса и обработки событий добавления/удаления устройств и сценариев.